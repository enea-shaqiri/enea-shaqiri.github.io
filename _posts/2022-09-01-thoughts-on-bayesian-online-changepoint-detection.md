---
layout: post
tags: bayesian paper_explained
mathjax: true
excerpt: hey there
title: "Thoughts on Bayesian online changepoint detection"
---

The article "Bayesian online changepoint detection" certainly has a title that makes it easy to sell: the authors are proposing an online changepoint detection method and this method is Bayesian! What else can you ask from life? To my surprise, the first time I approached this article I had to give up, because I couldn't really fill up some details myself. To be fair to the article, I was not that acquainted with the Bayesian way of seeing the world. Let's get mathy and explore the formulas and the core ideas in depth.

In my opinion, a good place to start is to give an idea of the problem the paper addresses, and start getting mathematical in the next section. Let $\{x_1, \dots, x_T\}$ be some observations (indexed by time) of some phenomenon we are interested in. The idea is that there is some underlying process evolving with time and we can measure some of its features. As time passes by, new data $\{x_{T+1}, x_{T+2}, \dots\}$ is observed (aka the quantities that we measure), and we want to find out (at each time $T + i$) if the characteristics of the process generating the data are "drastically" changing with time (hence the terminology changepoint/breakpoint). Now, the concept of "drastic change" is not well defined but we will get into that later, when exposing the assumptions. Of course we cannot know for sure if some changepoint has happened, so probabilities naturally enter the game. What the paper does it to provide a way to compute the probability that a changepoint is occurring at the current time $t$, for each $t$.

<h2>Notation, assumptions and formalisation of the problem</h2>

Let's get formal. Let $\{x_1, x_2 \dots, x_T\}$ be the data collected at time $T$. We want to sequentially partition this data in coherent groups across time, i.e. we want to find $A_1, \dots, A_m$ such that 
\\[
 \begin{aligned}
  A_i\cap A_j=\empty,\  \forall i, j,   \\\
  \cup_{i=1}^m A_i=\{x_1, \dots, x_T\},  \\\
  \text{if}\ s_1 \leq s_2 \leq s_3 \ \text{and}\ x_{s_1}, x_{s_3} \in A_i\ \text{then}\ x_{s_2}.
 \end{aligned}
\\]
We want our partitions to capture some relevant statistical features of the data. The most intuitive way of requiring statistical coherence is to ask for the datapoints in each partition to be generated by the same underlying distribution. Since we can choose our own assumptions we also require the datapoints to be independent. For each partition, we call the first point of the partition (the order being chronological) changepoint. The idea here is that in each partition there is an underlying distribution generating the data. We don't know a priori the shape of this distribution, but we can make better and better estimates about the distribution as new data comes in; and we use these estimates to estimate if a newly observed point is likely to have been generated by the same distribution or not.

To approach the problem of finding the changepoints, the article introduces a quantity, $r_t$, called the run length. For each $t$, $r_t$ is a natural number which measures the time steps since the last changepoint or, equivalently, the length up to time $t$ of the current partition. The value of $r_t$ represents the current run length at the end of the episode, that is after observing $x_t$. For instance, let's say we measure $x_1, x_2, x_3$ and we assume (for lack of better knowledge) that there was a changepoint right before the first data-point $x_1$ is observed. Let's say no other changepoint occurs between $x_1$ and $x_3$, then $r_1=1, \ r_2=2, r_3=3$. If a changepoint occurs at time $3$, then $r_1 =1,\ r_2=2$ and $r_3=0$. 

Notice also that $r_t$ can assume only two values 
\\[
 \begin{equation}
  \begin{cases}
   r_t  =r_{t-1} + 1 \ &\text{if no changepoint occurs at time }t\\\\
   r_t=0 \ &\text{otherwise}.
  \end{cases}
 \end{equation}
\\]

Since we don't really know when a changepoint occurs, we consider $r_t$ as a random variable, for each $t$. What the article does is provide an recursive formula $\mathbb{P}(r_t\vert x_1, \dots, x_t)$. 

 Before proceeding with the next section we introduce some more notation. We use $x_{s:t}$ to denote the set $\{x_s, x_{s+1}, \dots, x_t\}$, for some $s<t$. The article also defines $x^{(l)}$ to denote the datapoints related to $r_t=l$, that is the datapoints in the current partition, assuming the partition has $l$ points in it. I won't be using this notation as I think it is clearer to be explicit in this particular case.

### $\boldsymbol{\text{Conditional independence assumptions}}$

+ For each $t$ we assume $r_t$ to be independent of the data given the value of $r_{t-1}$, formally 
  \\[
   \mathbb{P}(r_t\vert r_{t-1}, x_{1:t}) = \mathbb{P}(r_t\vert r_{t-1}).
  \\]

+ For each $t$ we assume @TODO finish sentence


<h2>Base case</h2>

Instead of going directly for the formula let's start with the case that I found troublesome: how does this computation even start.

We are at time $t_0=0$, and we have yet to see a point, the first thing to do is to ask "what is the value of the current run length?". This question makes sense because if we are interested in an ongoing process, then we think the process exists even when we are not observing it (let's not get into [technicalities](https://cp3.irmp.ucl.ac.be/~maltoni/PHY1222/mermin_moon.pdf) here), thus its statistical properties are evolving through time. The convenient answer is $0$, but the truth is that $r_0$ can assume any nonnegative integer value. Let's assume is $0$ for now and come to this point later. At time $t_1=1$ we have one observation $x_1$. The only knowledge we have at this point is our prior guess, as we have not seen any other points. At time $t_2=2$ we reason as follows: 

* If there was a changepoint at $t_1$ then $r_1=0$ and $x_1$, $x_2$ come from two different distributions. The information that we acquired observing $x_1$ does not help us to say anything about $x_2$. In this case we are in a similar situation to having seen no datapoints, and we have to start afresh with a prior (a different one otherwise $x_1$ and $x_2$ would be drawn from the same distribution).
* If there is not a changepoint then $r_1=1$, and we can use $x_1$ to update our prior knowledge about the parameters generating the points in the current partition ($x_1$ and $x_2$).

Formally we are looking at $\mathbb{P}(x_2\vert x_1)$, where conditioning with respect to $x_1$ refers to updating our belief about the prior after seeing $x_1$ (here for more). We can use the law of total probability to write
\\[
 \begin{align}
  \mathbb{P}(x_2\vert x_1) &= \mathbb{P}(x_2, r_1=1\vert x_1) + \mathbb{P}(x_2, r_1=0\vert x_1) \\\  &=
  \mathbb{P}(x_2\vert r_1=1, x_1) \mathbb{P}(r_1=1\vert x_1) + \mathbb{P}(x_2\vert r_1=0, x_1) \mathbb{P}(r_1=0\vert x_1)
 \end{align}
\\]

Let's start with the second term in the sum. If there is a changepoint then $x_1$ contains no useful information about $x_2$ and thus $P(x_2\vert r_1=0, x_1)=P(x_2)$, which is the prior of $x_2$. We also have 
\\[
 \mathbb{P}(r_1=0\vert x_1)=\mathbb{P}(r_1\vert r_0=0, x_1)\mathbb{P}(r_0=0)=\mathbb{P}(r_1\vert r_0=0)\mathbb{P}(r_0=0)
\\]
where the second equality is obtained using the independence assumption stated at the end of the previous paragraph. 
Let's move to the first term in the sum. The second element can be worked out exactly as the second element in the second term of the sum. The first element of the sum can be written as 
\\[
 \mathbb{P}(x_2\vert r_1=1, x_1) = \int\mathbb{P}(x_2\vert r_1=1, \theta)\mathbb{P}(\theta\vert r_1=1, x_1)d\theta.
\\]
The formula is quite simple but the interpretation is at the heart of the Bayesian framework. By this I mean that in the r.h.s. we are summing over every possible parameter choice $\theta$ the probability (also called posterior in this context) that the new datapoint is generated from a distribution with some parameters $\theta$. But that's not all, we are $\mathcal{weighting}$ the posteriors by how probable it is to guess $\theta$ after seeing $x_1$ (also called likelihood in this case). This type of formula is so important that it has a name: predictive posterior.

 [That's the catch: there is not really any parameter update; what is updated is our belief of what values the parameters should assume after we have seen some data. (TALK ABOUT INDEPENDENCE AND MOVE THIS TO ANOTHER BLOG POST).]

The terms $\mathbb{P}(x_2\vert r_1=1, x_1)$, $\mathbb{P}(r_1\vert r_0=0)$  cannot be simplified further without additional assumptions. For the first term the paper assumes the priors to be from the exponential family, and it is well known result that the predictive posterior is also from the exponential family. If the chosen prior has no conjugate posterior approximate inference methods are required. For the second term the article 

This concludes our overview of the base case. The computation of $P(x_3\vert x_1, x_2)$ proceeds similarly, but let's not waste any further time and...

<h2>Let's get general</h2>

Some data $x_1, \dots, x_t$ has come in and we want to compute both $\mathbb{P}(x_{t+1}\vert x_{1:t})$ and $\mathbb{P}(r_t\vert x_{1:t})$, that is we make a prediction about the next point and also about the current run length. We have 
\\[
 \mathbb{P}(x_{t+1}\vert x_{1:t}) = \sum_{l=0}^\infty \mathbb{P}(x_{t+1}\vert r_t=l, x_{1:t}) \mathbb{P}(r_t=l\vert x_{1:t}).
\\]
Using the fact the $x_{t+1}$ is independent of the datapoints not in the current partition, and the fact the we are conditioning to $r_t=l$, we can write
\\[
 \mathbb{P}(x_{t+1}\vert r_t=l, x_{1:t}) = \mathbb{P}(x_{t+1}\vert r_t=l, \{x_{t-l + 1} ,\dots, x_t\}).
\\]
A remark about this part: $r_t$ can assume a value larger than $t$, which is the number of points observed up to now. This can happen because $r_0$ can be chosen to assume any value (the choice depending on the application). The sum goes from $0$ to $\infty$, because $r_t$ can a priori assume any value, but for a fixed $r_0$ and given $t$ the number of elements in the sum is at most $\max\{t, r_0\}$. The same reasoning applies to the other infinite sums we will come across.

Let's look at the second term. We can write it as
\\[
 \mathbb{P}(r_t=k\vert x_{1:t}) = \frac{\mathbb{P}(r_t=l, x_{1:t})}{\mathbb{P}(x_{1:t})} = \frac{\mathbb{P}(r_t=l, x_{1:t})}{\sum_{j=0}^\infty \mathbb{P}(r_t=j, x_{1:t})}.
\\]
The denominator has the same form as the numerator, so if we can compute the numerator we can compute also the denominator (keep in mind that the sum is finite). This is the important part of the paper, where the recursive formula is introduced to compute the numerator. We have
\\[
 \mathbb{P}(r_t=l, x_{1:t}) = \sum_{j=0}^{l-1}\mathbb{P}(r_t=k, r_{t-1}=l, x_t, x_{1:t-1})=\\ \sum_{j=0}^{l-1} \mathbb{P}(x_t\vert r_t={l},r_{t-1}=j, x_{1:t-1}) \mathbb{P}(r_t=l\vert r_{t-1}=j, x_{1:t-1}) \mathbb{P}(r_{t-1}=j, x_{1:t-1}).
\\]
Where the sum if finite since $r_{t-1}$ cannot be larger that $r_t$. The first equality is just the rule of total probability, and the second one comes from repeatedly conditioning. We observe that the last term has the same form of the numerator at time $t-1$, and this gives the recursive formula we were after. Moreover the above formula allows for efficient computation, since the pair $(r_t, r_{t-1})$ can only be of the form $(0, j)$, for some $j$, or $(l, l-1)$. Using our conditional independence assumptions we can simplify the first two term of the sum even further (we keep the notation with values $l$ and $j$ as if they could be generic, even if they satisfy some constraints)
\\[
 \begin{align}
  \mathbb{P}(x_t\vert r_t={l},r_{t-1}=j, x_{1:t-1})=\mathbb{P}(x_t\vert r_t={l},r_{t-1}=j, x_{t-l:t-1})=\mathbb{P}(x_t\vert r_t={l}, x_{t-l:t-1}),\\
  \mathbb{P}(r_t=l\vert r_{t-1}=j, x_{1:t})=\mathbb{P}(r_t=l\vert r_{t-1}=j).
 \end{align}
\\]

We are done with the recursive step. Let's see 

<h2>Initial conditions</h2>

As we have a recursive way to compute $\mathbb{P}(r_t=l, x_{1:t})$ that involves $\mathbb{P}(r_t=l\vert r_{t-1}=j)$, we need to set the value of $\mathbb{P}(r_0)$ to be able to compute all these terms. Above we assumed $\mathbb{P}(r_0 = 0) = 1$, which is convenient but not very realistic. The article proposes to use the normalised survival function for the distribution of $r_0$. Formally it proposes to write 
\\[
 \mathbb{P}(r_0=\tau) = \frac{1}{Z}\sum_{\tau'=\tau+1}^{\infty}\mathbb{P}(r_0=\tau'),
\\]
where $Z$ is the constant that makes $\mathbb{P}(r_t \geq 0) = 1$. The survival function can be estimated from the data (although it requires some assumptions of some type).

<h2>Wrapping it up</h2>

Ok, we have covered all the required steps to use the algorithm as presented in the paper. Let's put the pieces together in a step-by-step fashion.

**Step 1**. Fix all the needed priors: the changepoint prior $\mathbb{P}(r_t\vert r_{t-1})$, and the data prior $\mathbb{P}(x_t\vert r_t=0)$. In the article they are taken to be Geometric and Gaussian distribution respectively. Choose your initial conditions, that is $\mathbb{P}(r_0)$



 