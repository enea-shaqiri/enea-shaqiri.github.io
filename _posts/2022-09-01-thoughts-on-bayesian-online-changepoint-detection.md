---
layout: post
tags: bayesian paper_explained
mathjax: true
excerpt: hey there
title: "Thoughts on Bayesian online changepoint detection"
---



The article "Bayesian online changepoint detection" certainly has a title that makes it easy to sell: the authors are proposing an online changepoint detection method and this method is Bayesian! What else can you ask from life? To my surprise, the first time I approached this article I had to give up, because I couldn't really fill up some details myself. To be fair to the article, I was not that acquainted with the Bayesian way of seeing the world. Let's get mathy and explore the formulas and the core ideas in depth.
In my opinion, a good place to start is to give an idea of the problem the paper addresses, and start getting mathematical in the next section. Let $\{x_1, \dots, x_T\}$ be some observations (indexed by time) of some phenomenon we are interested in. The idea is that there is some underlying process evolving with time and we can measure some of its features. As time passes by, new data $\{x_{T+1}, x_{T+2}, \dots\}$ is observed (aka the quantities that we measure), and we want to find out (at each time $T + i$) if the characteristics of the process generating the data are "drastically" changing with time (hence the terminology changepoint/breakpoint). Now, the concept of "drastic change" is not well defined but we will get into that later, when exposing the assumptions. What the paper does it to provide a way to compute the probability that a changepoint is occurring at the current time $t$, for each $t$.

<h2><center>Notation, assumptions and formalisation of the problem</center></h2>

Let's get formal. Let $\{x_1, x_2 \dots, x_T\}$ be the data collected at time $T$. We want to sequentially partition this data in coherent groups across time, i.e. we want to find $A_1, \dots, A_m$ such that 
$$
\begin{align}
& A_i\cap A_j= \varnothing,\  \forall i, j,\\\ 
& \cup_{i=1}^m A_i=\{x_1, \dots, x_T\}, \\\ 
& \text{if}\ s_1 \leq s_2 \leq s_3 \ \text{and}\ x_{s_1}, x_{s_3} \in A_i\ \text{then}\ x_{s_2}.
\end{align}
$$
We want our partitions to capture some relevant statistical features of the data. The most intuitive way of requiring statistical coherence is to ask for the datapoints in each partition to be generated by the same underlying distribution. Since we can choose our own assumptions we also require the datapoints to be independent. For each partition, we call the first point of the partition (the order being chronological) changepoint. The idea here is that in each partition there is an underlying distribution generating the data. The first assumption regards the We don't know a priori the shape of this distribution, but we can make better and better estimates about the distribution as new data comes in; and we use these estimates to estimate if a newly observed point is likely to have been generated by the same distribution or not.

To approach the problem of finding the changpoints, the article introduces a quantity, $r_t$, called the run length. For each $t$, $r_t$ is a natural number which measures the time steps since the last changepoint or, equivalently, the length up to time $t$ of the current partition . For instance, let's say we measure $x_1, x_2, x_3$ and we assume (for lack of better knowledge) that there was a changepoint right before the first data-point $x_1$ is observed. Let's say no other changepoint occurs between $x_1$ and $x_3$, then $r_1=1, \ r_2=2, r_3=3$. If a changepoint occurs at time $3$, then $r_1 =1,\ r_2=2$ and $r_3=0$. 

Notice also that $r_t$ can assume only two values 
$$
\begin{equation}
\begin{cases}
r_t  =r_{t-1} + 1 \ &\text{if no changepoint occurs at time }t\\\\
r_t=0 \ &\text{otherwise}.
\end{cases}
\end{equation}
$$

Since we don't really know when a changepoint occurs we consider $r_t$ as a random variable for each $t$. What the article does is provide a recursive formula $\mathbb{P}(r_t\vert x_1, \dots, x_t)$. We also assume that given $r_{t-1}$, $r_t$ is independent of $x_{1:t}$, formally
$$
\mathbb{P}(r_t\vert r_{t-1}, x_{1:t}) = \mathbb{P}(r_t\vert r_{t-1}).
$$
 Before proceeding with the next section we introduce some more notation. We use $x_{s:t}$ to denote the set $\{x_s, x_{s+1}, \dots, x_t\}$, for some $s<t$. The article also defines $x^{(l)}$ to denote the datapoints related to $r_t=l$, that is the datapoints in the current partition, assuming the partition has $l$ points in it. I won't be using this notation as I think it is clearer to be explicit in this particular case.

<h2><center> Base case</center></h2>

Instead of going directly for the formula let's start with the case that I found troublesome: how does this computation even start.

We are at time $t=0$, and we have yet to see a point, the first thing to do is to ask the question "what is the value of the current run length?". This question makes sense because if we are interested in an ongoing process, then we think the process exists even when we are not observing it (let's not get into [technicalities](https://cp3.irmp.ucl.ac.be/~maltoni/PHY1222/mermin_moon.pdf) here), thus its statistical properties are evolving through time. The convenient answer is $0$, but the truth is that $r_0$ can assume any nonnegative integer value. Let's assume is $0$ for now and come to this point later. At time $t=1$ we have one observation $x_1$. The only knowledge we have at this point is our prior guess, as we have not seen any other points. $r_1$ can be $1$ or $0$, but it does not make a whole lot of sense for $r_1$ to be $0$. At time $t=2$ we reason as follows: 

* If there is a changepoint then $r_2=0$ and $x_1$, $x_2$ come from  $2$ different distributions. The information that we acquired observing $x_1$ does not help us to say anything about $x_2$. In this case we are in a similar situation to having seen no datapoints, and we have to start afresh with a prior (a different one otherwise $x_1$ and $x_2$ would be drawn from the same distribution).
* If there is not a changepoint then $r_2=2$, and we can use $x_1$ to update our prior knowledge about the parameters generating the points in the current partition ($x_1$ and $x_2$).

Formally we are looking at $\mathbb{P}(x_2\vert x_1)$, where conditioning with respect to $x_1$ refers to updating our belief about the prior after seeing $x_1$ (here for more). We can use the law of total probability to write
$$
\begin{align}\mathbb{P}(x_2\vert x_1) &= \mathbb{P}(x_2, r_2=2\vert x_1) + \mathbb{P}(x_2, r_2=0\vert x_1) \\ 
&=
\end{align}
\
$$


$$
\mathbb{P}(x_2\vert x_1) = \int\mathbb{P}(x_2\vert \theta)\mathbb{P}(\theta\vert x_1)d\theta.
$$
The formula is quite simple but the interpretation is at the heart of the Bayesian framework. By this I mean that in the r.h.s. we are summing over every possible parameter choice $\theta$ the probability (also called posterior in this context) that the new datapoint is generated from a distribution with some parameters $\theta$. But that's not all, we are $\mathcal{weighting}$ the posteriors by how probable it is to guess $\theta$ after seeing $x_1$ (also called likelihood in this case). That's the catch: there is not really any parameter update; what is updated is our belief of what values the parameters should assume after we have seen some data. (TALK ABOUT INDEPENDENCE AND MOVE THIS TO ANOTHER BLOG POST)







To find a formula for $\mathbb{P}(r_t\vert x_1, \dots, x_t)$ we use the good all marginalisation, some independence assumptions and a bit of intuition. For each $k\geq0$  we can write
$$
\mathbb{P}(r_t=k\vert x_{1:t}) = \frac{\mathbb{P}(r_t=k, x_{1:t})}{\mathbb{P}(x_{1:t})} = \frac{\mathbb{P}(r_t=k, x_{1:t})}{\sum_{j=0}^\infty \mathbb{P}(r_t=j, x_{1:t})},
$$

where we used the fact that $\{r_t=j\}$ are disjoint events. Let's consider the value of $k$ fixed for some $k > 0$ and let's focus on the numerator
$$
\mathbb{P}(r_t=k, x_{1:t}) = \sum_{j=0}^{k-1}\mathbb{P}(r_t=k, r_{t-1}=j, x_t, x_{1:t-1})=\\ \sum_{j=0}^{k-1} \mathbb{P}(x_t\vert r_t={k},r_{t-1}=j, x_{1:t-1}) \mathbb{P}(r_t=k\vert r_{t-1}=j, x_{1:t-1}) \mathbb{P}(r_{t-1}=j, x_{1:t-1}).
$$


The first equality is just the rule of total probability, and the second one comes from repeatedly conditioning. We observe that the last term has the same form of the numerator at time $t-1$, and this gives the recursive formula we were after. Moreover the above formula allows for efficient computation, since $r_t$ can assume only two values given $r_{t-1}$, thus most of the terms in the sum are $0$. Let's simplify the terms even further, using our initial assumptions.
$$
\mathbb{P}(x_t\vert r_t={k},r_{t-1}=j, x_{1:t-1})=\mathbb{P}(x_t\vert r_t={k},r_{t-1}=j, x_{t-j:t-1})=\mathbb{P}(x_t\vert r_t={k}, x_{t-j:t-1}).
$$
The first equality comes from the fact that the we are conditioning 

